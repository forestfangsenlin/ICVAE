{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b7cad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import gzip\n",
    "import pandas\n",
    "import h5py\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn import model_selection\n",
    "from scipy import stats\n",
    "\n",
    "from rdkit.Chem.Descriptors import ExactMolWt\n",
    "from rdkit.Chem.Crippen import MolLogP\n",
    "from rdkit.Chem.rdMolDescriptors import CalcNumHBD    \n",
    "from rdkit.Chem.rdMolDescriptors import CalcNumHBA\n",
    "from rdkit.Chem.rdMolDescriptors import CalcTPSA\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.QED import qed\n",
    "\n",
    "from utils import decode_smiles_from_indexes, load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, charset = load_dataset('./data/processed.h5')\n",
    "\n",
    "mw_train = np.load(\"./prop_np/weight/y_train_norm.npy\")\n",
    "mw_test = np.load(\"./prop_np/weight/y_test_norm.npy\")\n",
    "\n",
    "mw_pdf_train = np.load(\"./prop_np/weight/pdf_train.npy\")\n",
    "mw_pdf_test = np.load(\"./prop_np/weight/pdf_test.npy\")\n",
    "\n",
    "tpsa_train = np.load(\"./prop_np/tpsa/y_train_norm.npy\")\n",
    "tpsa_test = np.load(\"./prop_np/tpsa/y_test_norm.npy\")\n",
    "\n",
    "tpsa_pdf_train = np.load(\"./prop_np/tpsa/pdf_train.npy\")\n",
    "tpsa_pdf_test = np.load(\"./prop_np/tpsa/pdf_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aadb5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f9cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.zeros((len(mw_train), lat_dim))\n",
    "y_test = np.zeros((len(mw_test), lat_dim))\n",
    "\n",
    "y_train[:,0] = mw_train\n",
    "y_train[:,1] = tpsa_train\n",
    "\n",
    "y_test[:,0] = mw_test\n",
    "y_test[:,1] = tpsa_test\n",
    "\n",
    "y_train[:,2:] = 0.\n",
    "y_test[:,2:] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce78ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_train = np.concatenate((mw_pdf_train, tpsa_pdf_train),axis=-1)\n",
    "pdf_test = np.concatenate((mw_pdf_test, tpsa_pdf_test),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b364e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_X_train = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "torch_X_test = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "\n",
    "torch_pdf_train = torch.from_numpy(pdf_train).type(torch.FloatTensor) \n",
    "torch_pdf_test = torch.from_numpy(pdf_test).type(torch.FloatTensor)\n",
    "\n",
    "torch_y_train = torch.from_numpy(y_train).type(torch.FloatTensor) \n",
    "torch_y_test = torch.from_numpy(y_test).type(torch.FloatTensor)\n",
    "\n",
    "train = torch.utils.data.TensorDataset(torch_X_train, torch_pdf_train, torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test, torch_pdf_test, torch_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1d096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train, shuffle=True, batch_size=250)\n",
    "test_loader = torch.utils.data.DataLoader(test, shuffle=True, batch_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear_3 = nn.Linear(194, 256) ##161\n",
    "        self.linear_4 = nn.Linear(256, 1344)\n",
    "        self.conv_4 = nn.ConvTranspose2d(64,32, kernel_size=(11,3), stride=(2,2), padding=0,output_padding=(0,0))\n",
    "        self.conv_5 = nn.ConvTranspose2d(32,16, kernel_size=(11,3), stride=(2,2), padding=0,output_padding=(0,1))\n",
    "        self.conv_6 = nn.ConvTranspose2d(16,1, kernel_size=(11,3), stride=(2,2),padding=0,output_padding=(1,0))\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, z, y):\n",
    "        z_cond = torch.cat((z,y), dim=1)\n",
    "        z_cond = F.selu(self.linear_3(z_cond))\n",
    "        z_cond = F.selu(self.linear_4(z_cond))\n",
    "        z_cond = z_cond.view(z_cond.size(0), 64, 7, 3)# (N,C,H)\\n\",\n",
    "        z_cond = self.relu(self.conv_4(z_cond))\n",
    "        z_cond = self.relu(self.conv_5(z_cond))\n",
    "        z_cond = self.relu(self.conv_6(z_cond))\n",
    "        y0 = z_cond.contiguous().view(z_cond.size(0), -1) # (N,C,H)\\n\",\n",
    "        y1 = F.softmax(y0, dim=1)\n",
    "        y = y1.contiguous().view(z_cond.size(0), z_cond.size(2), z_cond.size(3))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53003061",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolecularVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MolecularVAE, self).__init__()\n",
    "\n",
    "        self.conv_1 = nn.Conv2d(1, 16, (11,3), stride=(2,2))\n",
    "        self.conv_2 =nn.Conv2d(16, 32, (11,3), stride=(2,2))\n",
    "        self.conv_3 = nn.Conv2d(32, 64, (11,3), stride=(2,2))\n",
    "        self.linear_0 = nn.Linear(1344, 256)\n",
    "        self.linear_1 = nn.Linear(256, lat_dim)\n",
    "        self.linear_2 = nn.Linear(256, lat_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.decode = Decoder()\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x = self.relu(self.conv_1(x))\n",
    "        x = self.relu(self.conv_2(x))\n",
    "        x = self.relu(self.conv_3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.selu(self.linear_0(x))\n",
    "        return self.linear_1(x), self.linear_2(x)\n",
    "    \n",
    "    def sampling(self, z_mean, z_logvar):\n",
    "        epsilon = 1e-2 * torch.randn_like(z_logvar)\n",
    "        return torch.exp(0.5 * z_logvar) * epsilon + z_mean\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x_cond = torch.cat((x,y.view(y.size(0), 1, 2, -1)), dim=2)\n",
    "        z_mean, z_logvar = self.encode(x_cond)\n",
    "        z = self.sampling(z_mean, z_logvar)\n",
    "        decoder = self.decode(z, y)\n",
    "        \n",
    "        return decoder, z_mean, z_logvar,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef9b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x_decoded_mean, x, z_mean, z_logvar, y_arg):\n",
    "    xent_loss = F.binary_cross_entropy(x_decoded_mean, x, size_average=False)\n",
    "    kl_loss = -0.5 * torch.sum(1 + z_logvar - (z_mean-y_arg).pow(2) - z_logvar.exp())\n",
    "    return 0.1*xent_loss + 0.1*kl_loss, 0.1*kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "epochs = 100\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = MolecularVAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb2ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    KL_loss = 0\n",
    "    latent_arr = []\n",
    "    label_arr = []\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        oh, label, arg_label = data\n",
    "        oh, label, arg_label = oh.unsqueeze(1).to(device), label.to(device), arg_label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, mean, logvar,latent = model(oh, label)\n",
    "        loss, kl_loss = vae_loss(output, oh.squeeze(1), mean, logvar, arg_label)\n",
    "        loss.backward()\n",
    "        train_loss += loss\n",
    "        KL_loss+=kl_loss\n",
    "        optimizer.step()\n",
    "        latent_arr.append(latent.cpu().detach().numpy())\n",
    "        label_arr.append(arg_label.cpu().detach().numpy())\n",
    "        \n",
    "    print('train', train_loss / len(train_loader.dataset))\n",
    "    print('train KL', KL_loss / len(train_loader.dataset))\n",
    "    \n",
    "    return train_loss / len(train_loader.dataset),latent_arr, label_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a0db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    KL_loss = 0\n",
    "    for batch_idx, data in enumerate(test_loader):\n",
    "        oh, label, arg_label = data\n",
    "        oh, label, arg_label = oh.unsqueeze(1).to(device), label.to(device), arg_label.to(device)\n",
    "        output, mu, logvar,latent = model(oh, label)\n",
    "\n",
    "        loss, kl_loss = vae_loss(output, oh.squeeze(1), mu, logvar, arg_label)\n",
    "        KL_loss+=kl_loss\n",
    "        test_loss += loss\n",
    "    print('test', test_loss / len(test_loader.dataset))\n",
    "    print('test KL', KL_loss / len(test_loader.dataset))\n",
    "    \n",
    "    return test_loss / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72befae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss,latent_arr,label_arr = train(epoch)\n",
    "    test_loss = test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740aa8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_np = np.array(latent_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_np = latent_np[:,:,:2].reshape((-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1b5e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_np = np.array(label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_np = label_np[:,:,:2].reshape((-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79d9244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95878ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(label_np[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c558e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.max(latent_np[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd4fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb9049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(latent_np[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612a19cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56cf5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_ord = np.sqrt(label_np[:,0]**2+(label_np[:,1])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f70698",
   "metadata": {},
   "source": [
    "np.save(\"./prop_np/hba_hbd/latent.npy\", latent_np)\n",
    "np.save(\"./prop_np/hba_hbd/label.npy\", label_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_ord.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bbe454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "latten_pd = pd.DataFrame({\n",
    "        'x': latent_np[:, 0]/10,\n",
    "        'y': latent_np[:, 1]/10,\n",
    "        'label': cor_ord})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976aa3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = latten_pd.plot(kind=\"scatter\", x='x', y='y', alpha=0.7, figsize=(10,7),\n",
    "    c='label', cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
    "    sharex=False)\n",
    "\n",
    "#im.axes.set_title(\"CVAE Latent Distribution\",y=1.05, fontsize=25)\n",
    "im.set_xlabel(\"normalized HBA\",fontsize=20)\n",
    "im.set_ylabel(\"normalized HBD\",fontsize=20)\n",
    "im.tick_params(labelsize=20)\n",
    "\n",
    "\n",
    "#plt.savefig(\"./image/HBA_HBD.jpg\", format='jpg',edgecolor='none', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349d1eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    " def reconstructed(autoencoder, charset):\n",
    "    valid_smile = []\n",
    "    true_value = 3.5\n",
    "    prop1 = 5\n",
    "    prop2 = 250\n",
    "    nums = 1000\n",
    "    x = np.linspace(0, 10, 33)\n",
    "\n",
    "    for i in range(1000):\n",
    "        \n",
    "        re_smile = []\n",
    "        lat =  np.random.normal(0, 1., size=(nums, 128)).astype ('float32')    \n",
    "        lat[:,0] = lat[:,0] + (np.ones((nums))*prop1)\n",
    "        lat[:,1] = lat[:,1] + (np.ones((nums))*prop2)\n",
    "\n",
    "        cond1 = stats.norm(prop1, 1).pdf(x)\n",
    "        \n",
    "        cond2 = stats.norm(prop2, 1).pdf(x)\n",
    "        \n",
    "        cond = np.concatenate((cond1,cond2),axis=-1)\n",
    "\n",
    "        cond_repeat = np.repeat(cond[np.newaxis, :], nums, axis=0)\n",
    "        \n",
    "        \n",
    "        lat_torch =  torch.Tensor(lat).to(device)\n",
    "        cond_torch =  torch.Tensor(cond_repeat).to(device)\n",
    "        \n",
    "        output = autoencoder.decode(lat_torch,cond_torch)\n",
    "        outp = output.cpu().detach().numpy()\n",
    "        \n",
    "        for j in range(nums):\n",
    "            decode_smi = outp[j].reshape(1, 120, len(charset)).argmax(axis=2)[0]\n",
    "            re_smile.append(decode_smiles_from_indexes(decode_smi, charset))\n",
    "        \n",
    "        for k in range(len(re_smile)):\n",
    "            m = Chem.MolFromSmiles(re_smile[k])\n",
    "            if (m != None) and (' ' not in re_smile[k]):\n",
    "                valid_smile.append(re_smile[k])\n",
    "                \n",
    "    valid_smile = list(set(valid_smile))\n",
    "        \n",
    "    return valid_smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1509f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import RDLogger   \n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7291db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_smile = reconstructed(model, charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93178de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_tpsa = np.zeros((len(valid_smile),2))\n",
    "for i in range(len(valid_smile)):\n",
    "    s = valid_smile[i]\n",
    "    m = Chem.MolFromSmiles(s)\n",
    "    mw_tpsa[i,0] = ExactMolWt(m)\n",
    "    mw_tpsa[i,1] = CalcTPSA(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f2d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_tpsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50369bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
